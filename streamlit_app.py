#!/usr/bin/env python3
"""
YOLO Video Object Detection App - Streamlit Cloud Compatible Version
Uses alternative approach to avoid OpenCV/NumPy compatibility issues
"""

import streamlit as st
import numpy as np
import time
import os
import tempfile
from PIL import Image
import json
import plotly.express as px
import plotly.graph_objects as go
import base64
from io import BytesIO

# Page configuration
st.set_page_config(
    page_title="Video Object Detection",
    page_icon="üé•",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for better styling
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #1f77b4;
    }
    .detection-box {
        border: 2px solid #1f77b4;
        border-radius: 0.5rem;
        padding: 1rem;
        margin: 1rem 0;
    }
    .success-box {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        border-radius: 0.5rem;
        padding: 1rem;
        margin: 1rem 0;
    }
    .info-box {
        background-color: #d1ecf1;
        border: 1px solid #bee5eb;
        border-radius: 0.5rem;
        padding: 1rem;
        margin: 1rem 0;
    }
    .warning-box {
        background-color: #fff3cd;
        border: 1px solid #ffeaa7;
        border-radius: 0.5rem;
        padding: 1rem;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

def get_file_download_link(file_path, file_name, button_text):
    """Generate a download link for a file"""
    try:
        with open(file_path, "rb") as f:
            data = f.read()
        b64 = base64.b64encode(data).decode()
        href = f'<a href="data:application/octet-stream;base64,{b64}" download="{file_name}">{button_text}</a>'
        return href
    except Exception as e:
        st.error(f"Error creating download link: {e}")
        return None

def create_mock_detection_results(video_name, confidence_threshold=0.5):
    """Create mock detection results for demonstration"""
    # This is a placeholder - in a real implementation, you would use a working detection library
    import random
    
    # Mock classes that might be detected
    possible_classes = ['person', 'car', 'truck', 'bus', 'motorcycle', 'bicycle', 'dog', 'cat']
    
    # Generate mock results
    total_frames = random.randint(30, 120)  # 1-4 seconds at 30fps
    total_detections = 0
    class_counts = {}
    frame_analysis = {}
    
    for frame_id in range(total_frames):
        # Random number of detections per frame
        num_detections = random.randint(0, 3) if random.random() > 0.3 else 0
        
        frame_detections = []
        for _ in range(num_detections):
            class_name = random.choice(possible_classes)
            confidence = random.uniform(confidence_threshold, 0.95)
            
            # Only count detections above threshold
            if confidence >= confidence_threshold:
                class_counts[class_name] = class_counts.get(class_name, 0) + 1
                total_detections += 1
                
                frame_detections.append({
                    'class': class_name,
                    'confidence': confidence,
                    'bbox': [random.uniform(0, 1) for _ in range(4)]  # Mock bbox
                })
        
        if frame_detections:
            frame_analysis[frame_id] = frame_detections
    
    processing_time = random.uniform(2.0, 8.0)
    
    return {
        'total_detections': total_detections,
        'total_frames': total_frames,
        'processing_time': processing_time,
        'fps': total_frames / processing_time,
        'class_counts': class_counts,
        'frame_analysis': frame_analysis,
        'model_used': 'mock_detector',
        'video_name': video_name
    }

def process_video_stream(video_file, confidence_threshold=0.5, model_name="mock"):
    """Process uploaded video file - currently uses mock detection"""
    # Create temporary file
    with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp_file:
        tmp_file.write(video_file.read())
        temp_video_path = tmp_file.name
    
    try:
        # For now, use mock detection since ultralytics has OpenCV dependency issues
        start_time = time.time()
        
        # Show warning about mock detection
        st.warning("""
        ‚ö†Ô∏è **Note**: Currently using mock detection results due to OpenCV compatibility issues on Streamlit Cloud.
        
        In a production environment, you would integrate with a working object detection library.
        The mock results demonstrate the interface and visualization capabilities.
        """)
        
        # Generate mock results
        summary = create_mock_detection_results(video_file.name, confidence_threshold)
        
        # Clean up temporary input file
        os.unlink(temp_video_path)
        
        return summary, None, "mock_output"
        
    except Exception as e:
        st.error(f"Error processing video: {e}")
        if os.path.exists(temp_video_path):
            os.unlink(temp_video_path)
        return None, None, None

def create_detection_chart(class_counts):
    """Create a bar chart of detections"""
    if not class_counts:
        return None
    
    # Prepare data for plotting
    classes = list(class_counts.keys())
    counts = list(class_counts.values())
    
    # Create bar chart
    fig = px.bar(
        x=classes,
        y=counts,
        title="Object Detection Results",
        labels={'x': 'Object Class', 'y': 'Number of Detections'},
        color=counts,
        color_continuous_scale='viridis'
    )
    
    fig.update_layout(
        xaxis_tickangle=-45,
        height=400
    )
    
    return fig

def create_confidence_distribution(frame_analysis):
    """Create confidence distribution chart"""
    if not frame_analysis:
        return None
    
    # Collect all confidence scores
    confidences = []
    for frame_data in frame_analysis.values():
        for det in frame_data:
            confidences.append(det['confidence'])
    
    if not confidences:
        return None
    
    # Create histogram
    fig = px.histogram(
        x=confidences,
        title="Confidence Score Distribution",
        labels={'x': 'Confidence Score', 'y': 'Number of Detections'},
        nbins=20
    )
    
    fig.update_layout(height=400)
    
    return fig

def create_detection_timeline(frame_analysis):
    """Create a timeline of detections across frames"""
    if not frame_analysis:
        return None
    
    # Prepare data
    frames = []
    detection_counts = []
    
    for frame_id in sorted(frame_analysis.keys()):
        frames.append(frame_id)
        detection_counts.append(len(frame_analysis[frame_id]))
    
    if not frames:
        return None
    
    # Create line chart
    fig = px.line(
        x=frames,
        y=detection_counts,
        title="Detections Over Time",
        labels={'x': 'Frame Number', 'y': 'Number of Detections'}
    )
    
    fig.update_layout(height=400)
    
    return fig

def main():
    # Header
    st.markdown('<h1 class="main-header">üé• Video Object Detection</h1>', unsafe_allow_html=True)
    
    # Sidebar
    st.sidebar.title("‚öôÔ∏è Settings")
    
    # Model selection (placeholder for now)
    model_option = st.sidebar.selectbox(
        "Detection Method",
        ["Mock Detection", "YOLO (Coming Soon)", "Custom Model (Coming Soon)"],
        help="Choose the detection method. Currently using mock detection for demonstration."
    )
    
    # Confidence threshold
    confidence_threshold = st.sidebar.slider(
        "Confidence Threshold",
        min_value=0.1,
        max_value=0.9,
        value=0.5,
        step=0.05,
        help="Lower threshold catches more objects, higher threshold is more selective"
    )
    
    # Main content
    tab1, tab2, tab3 = st.tabs(["üìπ Upload Video", "üìä Results Analysis", "‚ÑπÔ∏è About"])
    
    with tab1:
        st.header("Upload Video for Object Detection")
        
        # File uploader
        uploaded_file = st.file_uploader(
            "Choose a video file",
            type=['mp4', 'avi', 'mov', 'mkv'],
            help="Upload a video file to detect objects"
        )
        
        if uploaded_file is not None:
            # Show file info
            file_size = uploaded_file.size / (1024*1024)
            st.info(f"üìÅ File: {uploaded_file.name} ({file_size:.2f} MB)")
            
            # Process button
            if st.button("üöÄ Detect Objects", type="primary"):
                with st.spinner("Processing video..."):
                    summary, results, output_dir = process_video_stream(
                        uploaded_file, confidence_threshold, model_option
                    )
                
                if summary:
                    st.success("‚úÖ Video processing completed!")
                    
                    # Store results in session state
                    st.session_state.summary = summary
                    st.session_state.results = results
                    st.session_state.output_dir = output_dir
                    st.session_state.video_name = uploaded_file.name
                    
                    # Show quick summary
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("Total Detections", summary['total_detections'])
                    with col2:
                        st.metric("Processing Time", f"{summary['processing_time']:.2f}s")
                    with col3:
                        st.metric("FPS", f"{summary['fps']:.1f}")
                    with col4:
                        st.metric("Method Used", summary['model_used'])
                else:
                    st.error("‚ùå Processing failed. Please check the video file and try again.")
    
    with tab2:
        st.header("üìä Detection Results Analysis")
        
        if 'summary' in st.session_state:
            summary = st.session_state.summary
            
            # Detection summary
            st.subheader("üìà Detection Summary")
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown(f"""
                <div class="metric-card">
                    <h4>Statistics</h4>
                    <p><strong>Total Detections:</strong> {summary['total_detections']:,}</p>
                    <p><strong>Processing Time:</strong> {summary['processing_time']:.2f} seconds</p>
                    <p><strong>Total Frames:</strong> {summary['total_frames']:,}</p>
                    <p><strong>FPS:</strong> {summary['fps']:.1f}</p>
                    <p><strong>Method Used:</strong> {summary['model_used']}</p>
                </div>
                """, unsafe_allow_html=True)
            
            with col2:
                st.subheader("Object Classes Detected")
                if summary['class_counts']:
                    for class_name, count in sorted(summary['class_counts'].items(), key=lambda x: x[1], reverse=True):
                        percentage = (count / summary['total_detections']) * 100
                        st.write(f"**{class_name}**: {count:,} ({percentage:.1f}%)")
                else:
                    st.info("No objects detected")
            
            # Charts
            st.subheader("üìä Visualizations")
            
            # Detection chart
            if summary['class_counts']:
                chart = create_detection_chart(summary['class_counts'])
                if chart:
                    st.plotly_chart(chart, use_container_width=True)
            
            # Confidence distribution
            if 'frame_analysis' in summary:
                conf_chart = create_confidence_distribution(summary['frame_analysis'])
                if conf_chart:
                    st.plotly_chart(conf_chart, use_container_width=True)
                
                # Timeline chart
                timeline_chart = create_detection_timeline(summary['frame_analysis'])
                if timeline_chart:
                    st.plotly_chart(timeline_chart, use_container_width=True)
            
            # Download section
            st.subheader("üì• Download Results")
            
            # Create JSON results for download
            json_data = json.dumps(summary, indent=2)
            st.download_button(
                label="üìÑ Download JSON Results",
                data=json_data,
                file_name=f"detection_results_{summary['video_name']}.json",
                mime="application/json"
            )
            
            # Mock video download (placeholder)
            st.info("üìπ Processed video download will be available when real detection is implemented")
        
        else:
            st.info("Please upload and process a video first to see results.")
    
    with tab3:
        st.header("‚ÑπÔ∏è About This System")
        
        st.markdown("""
        ### üéØ Video Object Detection System
        
        This system provides object detection for video files. Currently using mock detection for demonstration purposes.
        
        ### üöÄ Features
        
        - **Multiple Detection Methods**: Support for different detection approaches
        - **Adjustable Confidence**: Fine-tune detection sensitivity
        - **Real-time Processing**: Fast video processing with progress tracking
        - **Comprehensive Analysis**: Detailed detection statistics and visualizations
        - **Export Capabilities**: Save detection results as JSON
        
        ### üìã Current Status
        
        **‚ö†Ô∏è Mock Detection Mode**: Due to OpenCV compatibility issues on Streamlit Cloud, 
        the system currently uses mock detection results to demonstrate the interface.
        
        ### üîß Technical Implementation Options
        
        To implement real object detection, consider these alternatives:
        
        1. **TensorFlow.js**: Browser-based detection (no server dependencies)
        2. **ONNX Runtime**: Lightweight inference engine
        3. **Custom Docker**: Containerized environment with compatible dependencies
        4. **API Integration**: External detection service
        
        ### üöÄ How to Use (Current)
        
        1. Upload a video file (MP4, AVI, MOV, MKV)
        2. Adjust confidence threshold
        3. Click "Detect Objects"
        4. View mock results and visualizations
        5. Download JSON results
        
        ### üí° Future Enhancements
        
        - Real object detection integration
        - Multiple model support
        - Video processing with annotations
        - Real-time streaming detection
        - Custom model training interface
        
        ### üîß Troubleshooting
        
        - **No detections**: Try lowering the confidence threshold
        - **File format issues**: Convert to MP4 format if needed
        - **Performance issues**: Use shorter videos for testing
        
        ### üìû Support
        
        For real object detection implementation, consider:
        - Using a different hosting platform with full dependency support
        - Implementing browser-based detection
        - Using external API services
        """)
    
    # Footer
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; padding: 1rem;">
        <p><strong>Video Object Detection System</strong> | Streamlit Cloud Compatible</p>
        <p>Mock detection mode - Real detection coming soon!</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
